{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "train_data,test_data = train_test_split(data, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    #add a constant column\n",
    "    data['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    data_features = data[features]\n",
    "    feature_matrix = data_features.as_matrix()\n",
    "    output_array = data[output]\n",
    "    output_matrix = output_array.as_matrix()\n",
    "    return (feature_matrix, output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(example_features, example_output) = get_numpy_data(data, ['sqft_living'], 'price') \n",
    "# the [] around 'sqft_living' makes it a list\n",
    "print example_features # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print example_output # and the corresponding output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_weights = np.array([1., 1.]) #example_weights\n",
    "my_features = example_features[0,]\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "print predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "     # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print test_predictions[0]\n",
    "print test_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative = 2 * np.dot(errors, feature)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(example_features, example_output) = get_numpy_data(data, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0.,0.])\n",
    "test_predictions = predict_output(example_features, my_weights)\n",
    "errors = test_predictions - example_output\n",
    "feature = example_features[:,0]\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print derivative\n",
    "print -np.sum(example_output)*2 # should be the same as derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, i])\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i]= weights[i] - (step_size * derivative)\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            derivative_square = derivative * derivative \n",
    "            gradient_sum_squares = derivative_square.sum()\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test out the gradient descent as simple regression\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "\n",
    "test_weight = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "print test_weight\n",
    "\n",
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)\n",
    "prediction = predict_output(test_simple_feature_matrix, test_weight)\n",
    "print 'prediction: ',prediction\n",
    "print 'prediction_sum: ',prediction.sum()\n",
    "print 'output: ',test_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using gradient descent for multiple regression\n",
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9\n",
    "test_weight_multiple = regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "(test_simple_feature_matrix_multiple, test_output_multiple) = get_numpy_data(test_data, model_features, my_output)\n",
    "prediction_multiple = predict_output(test_simple_feature_matrix_multiple, test_weight_multiple)\n",
    "print 'weights: ',test_weight_multiple\n",
    "print 'prediction_multiple: ',prediction_multiple\n",
    "print 'prediction_multiple_sum: ',prediction_multiple.sum()\n",
    "print 'output_multiple: ',test_output_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using scikit_learn for simple regression\n",
    "test_feature = test_data[simple_features].values.reshape(-1,1)\n",
    "test_output = test_data['price'].values.reshape(-1,1)\n",
    "train_feature = train_data[simple_features].values.reshape(-1,1)\n",
    "train_output = train_data['price'].values.reshape(-1,1)\n",
    "regr = linear_model.LinearRegression(fit_intercept=True)\n",
    "regr.fit(train_feature, train_output)\n",
    "prediction = regr.predict(test_feature)\n",
    "print 'prediction: ',prediction\n",
    "print 'prediction_sum: ',prediction.sum()\n",
    "print 'intercept',regr.intercept_\n",
    "print 'coefficients',regr.coef_\n",
    "print ('R^2: ',regr.score(train_output , train_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using scikit learn for multiple regression\n",
    "test_feature_multiple = test_data[model_features].values.reshape(-1,2)\n",
    "test_output_multiple = test_data['price'].values.reshape(-1,1)\n",
    "train_feature_multiple = train_data[model_features].values.reshape(-1,2)\n",
    "train_output_multiple = train_data['price'].values.reshape(-1,1)\n",
    "regr = linear_model.LinearRegression(fit_intercept=True)\n",
    "regr.fit(train_feature_multiple, train_output_multiple)\n",
    "prediction = regr.predict(test_feature_multiple)\n",
    "\n",
    "print 'prediction: ',prediction\n",
    "print 'prediction_sum: ',prediction.sum()\n",
    "print 'intercept',regr.intercept_\n",
    "print 'coefficients',regr.coef_\n",
    "# print ('R^2: ',regr.score(outputs , simple_feature))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
