{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('SSt:',SST)? (<ipython-input-2-e8a66b2be532>, line 97)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-e8a66b2be532>\"\u001b[1;36m, line \u001b[1;32m97\u001b[0m\n\u001b[1;33m    print 'SSt:',SST\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('SSt:',SST)?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "data = pd.read_csv('nba_ht_wt.csv',encoding ='ISO-8859-1')\n",
    "print(data.head())\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "# print (len(train),len(test))\n",
    "height = data['Height']\n",
    "weight = data['Weight']\n",
    "height = height.values.reshape(-1,1)\n",
    "weight = weight.values.reshape(-1,1)\n",
    "print (height.mean())\n",
    "\n",
    "train_height = train['Height']\n",
    "train_weight = train['Weight']\n",
    "test_height = test['Height']\n",
    "test_weight = test['Weight']\n",
    "test_weight = test_weight.values.reshape(-1,1)\n",
    "test_height = test_height.values.reshape(-1,1)\n",
    "train_weight = train_weight.values.reshape(-1,1)\n",
    "train_height = train_height.values.reshape(-1,1)\n",
    "\n",
    "## using scikit_learn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_weight, train_height)\n",
    "prediction = regr.predict(test_weight)\n",
    "print(prediction)\n",
    "print ('R^2: ',regr.score(weight , height))\n",
    "\n",
    "# print(height.mean())\n",
    "# plt.plot(height,'.')\n",
    "# plt.axhline(height.mean())\n",
    "# plt.show()\n",
    "\n",
    "## without sciki\n",
    "def simple_linear_regression(input_feature, output):\n",
    "    # compute the sum of input_feature and output\n",
    "    input_feature_sum = input_feature.sum()\n",
    "    output_sum = output.sum()\n",
    "    input_feature_mean = input_feature.mean()\n",
    "    \n",
    "    # compute the product of the output and the input_feature and its sum\n",
    "    output_input_product = input_feature*output\n",
    "    output_input_product_sum = output_input_product.sum()\n",
    "    \n",
    "    # compute the squared value of the input_feature and its sum\n",
    "    squared_input = input_feature * input_feature\n",
    "    squared_input_sum = squared_input.sum()\n",
    "    \n",
    "    # use the formula for the slope\n",
    "    ### using closed form solution\n",
    "#     slope = (output_input_product_sum-((input_feature_sum*output_sum)/len(input_feature)))/(squared_input_sum-((input_feature_sum*input_feature_sum)/len(input_feature)))\n",
    "    ### using correlation furmula\n",
    "    slope = ((input_feature-input_feature_mean) * (output - output.mean())).sum()/((input_feature-input_feature_mean)**2).sum()\n",
    "    \n",
    "    \n",
    "    # use the formula for the intercept\n",
    "    intercept = (output_sum - (slope * input_feature_sum))/len(input_feature)\n",
    "    \n",
    "    return (intercept, slope)\n",
    "\n",
    "intercept,slope = simple_linear_regression(train_weight, train_height)\n",
    "print(intercept, slope)\n",
    "\n",
    "def get_regression_predictions(input_feature, intercept, slope):\n",
    "    # calculate the predicted values:\n",
    "    predicted_values = intercept + (input_feature * slope)\n",
    "    \n",
    "    return predicted_values\n",
    "\n",
    "def get_residual_sum_of_squares(input_feature, output, intercept, slope):\n",
    "    # First get the predictions\n",
    "    predicted_values = intercept + (input_feature * slope)\n",
    "\n",
    "    # then compute the residuals (since we are squaring it doesn't matter which order you subtract)\n",
    "    residuals = output - predicted_values\n",
    "\n",
    "    # square the residuals and add them up\n",
    "    residuals_product = residuals * residuals\n",
    "    RSS = residuals_product.sum()\n",
    "\n",
    "    return RSS \n",
    "\n",
    "def total_sum_of_squares(output_feature):\n",
    "    SST = 0\n",
    "    error= (output_feature - output_feature.mean())**2\n",
    "    SST = error.sum()\n",
    "    return SST\n",
    "\n",
    "SST = total_sum_of_squares(height)\n",
    "SSE = get_residual_sum_of_squares(weight, height, intercept, slope)\n",
    "SSR = SST - SSE\n",
    "R_squared = (SSR / (SSR + SSE))\n",
    "\n",
    "print ('SSt:',SST)\n",
    "print ('RSS', SSE)\n",
    "print ('SSR', SSR)\n",
    "print ('R_squared', R_squared)\n",
    "\n",
    "prediction_ = get_regression_predictions(test_weight,intercept,slope)\n",
    "print(prediction_)\n",
    "print(test)\n",
    "plt.plot(prediction, prediction_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('P031.csv',encoding ='ISO-8859-1')\n",
    "print(data)\n",
    "\n",
    "input_feature = data['Units']\n",
    "output = data['Minutes']\n",
    "intercept1, slope1 = simple_linear_regression(input_feature, output)\n",
    "prediction = get_regression_predictions(input_feature, intercept1, slope1)\n",
    "print prediction\n",
    "plt.plot(input_feature, prediction)\n",
    "plt.scatter(input_feature, output)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
